"""
ìŠ¤ì¼€ì¤„ëŸ¬ ì‘ì—… ì •ì˜

APSchedulerë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ê¸° ì‘ì—…ì„ ìë™ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.
"""

from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
import logging
from datetime import datetime
import sys
from pathlib import Path

from app.api.dependencies import get_trigger_service, get_report_service, get_data_service, get_analysis_service

logger = logging.getLogger(__name__)

# ê¸€ë¡œë²Œ ìŠ¤ì¼€ì¤„ëŸ¬ ì¸ìŠ¤í„´ìŠ¤
scheduler = AsyncIOScheduler()


# ============= ì‘ì—… í•¨ìˆ˜ =============

async def run_morning_triggers_job():
    """ì˜¤ì „ íŠ¸ë¦¬ê±° ì‹¤í–‰ (09:10, í‰ì¼)"""
    try:
        logger.info("â° [ì˜¤ì „ íŠ¸ë¦¬ê±°] ì‹œì‘")
        trigger_service = get_trigger_service()
        today = datetime.now()

        results = await trigger_service.run_morning_triggers(today)
        total = sum(len(v) for v in results.values())

        logger.info(f"âœ… [ì˜¤ì „ íŠ¸ë¦¬ê±°] ì™„ë£Œ - {total}ê°œ ì¢…ëª© ê°ì§€")
    except Exception as e:
        logger.error(f"âŒ [ì˜¤ì „ íŠ¸ë¦¬ê±°] ì‹¤íŒ¨: {e}", exc_info=True)


async def run_afternoon_triggers_job():
    """ì˜¤í›„ íŠ¸ë¦¬ê±° ì‹¤í–‰ (15:30, í‰ì¼)"""
    try:
        logger.info("â° [ì˜¤í›„ íŠ¸ë¦¬ê±°] ì‹œì‘")
        trigger_service = get_trigger_service()
        today = datetime.now()

        results = await trigger_service.run_afternoon_triggers(today)
        total = sum(len(v) for v in results.values())

        logger.info(f"âœ… [ì˜¤í›„ íŠ¸ë¦¬ê±°] ì™„ë£Œ - {total}ê°œ ì¢…ëª© ê°ì§€")

        # ê¸‰ë“±/ê¸‰ë½ 10% ì´ìƒ ì¢…ëª© ìºì‹œ ë¬´íš¨í™”
        await check_surge_and_invalidate_cache_job()

    except Exception as e:
        logger.error(f"âŒ [ì˜¤í›„ íŠ¸ë¦¬ê±°] ì‹¤íŒ¨: {e}", exc_info=True)


async def check_surge_and_invalidate_cache_job():
    """
    ê¸‰ë“±/ê¸‰ë½ 10% ì´ìƒ ì¢…ëª©ì˜ ë¶„ì„ ìºì‹œ ë¬´íš¨í™”

    ì¥ ë§ˆê° í›„ 10% ì´ìƒ ë“±ë½í•œ ì¢…ëª©ì˜ ë¶„ì„ ìºì‹œë¥¼ ë¬´íš¨í™”í•˜ì—¬
    ë‹¤ìŒ ë¶„ì„ ìš”ì²­ ì‹œ ìµœì‹  ë°ì´í„°ë¡œ ì¬ìƒì„±ë˜ë„ë¡ í•¨
    """
    try:
        logger.info("â° [ìºì‹œ ë¬´íš¨í™”] ê¸‰ë“±/ê¸‰ë½ 10% ì²´í¬ ì‹œì‘")

        data_service = get_data_service()
        analysis_service = get_analysis_service()
        today = datetime.now()

        # í•„í„° í†µê³¼ ì¢…ëª© ì‹¤ì‹œê°„ ê°€ê²© ì¡°íšŒ (ì§ì ‘ ì¿¼ë¦¬ íŒ¨í„´)
        try:
            from app.db.database import get_db
            from app.db.models import FinancialData

            # 1. í•„í„° í†µê³¼ ì¢…ëª© ì¡°íšŒ
            with get_db() as db:
                tickers = [row.ticker for row in db.query(FinancialData).filter_by(filter_status='pass').all()]

            if not tickers:
                logger.warning("[ìºì‹œ ë¬´íš¨í™”] í•„í„° í†µê³¼ ì¢…ëª© ì—†ìŒ")
                return

            logger.debug(f"[ìºì‹œ ë¬´íš¨í™”] {len(tickers)}ê°œ ì¢…ëª© ì¡°íšŒ ì‹œì‘")

            # 2. ì‹¤ì‹œê°„ ê°€ê²© ë°°ì¹˜ ì¡°íšŒ
            realtime_prices = await data_service.get_realtime_prices_bulk(tickers)

            if not realtime_prices:
                logger.warning("[ìºì‹œ ë¬´íš¨í™”] ì‹¤ì‹œê°„ ê°€ê²© ë°ì´í„° ì—†ìŒ")
                return

            # 3. 10% ì´ìƒ ê¸‰ë“±/ê¸‰ë½ í•„í„°ë§
            surge_tickers = []
            plunge_tickers = []

            for ticker, price_data in realtime_prices.items():
                change_rate = price_data.get('change_rate', 0.0)
                if change_rate >= 10.0:
                    surge_tickers.append(ticker)
                elif change_rate <= -10.0:
                    plunge_tickers.append(ticker)

            all_extreme_tickers = surge_tickers + plunge_tickers

            if not all_extreme_tickers:
                logger.info("[ìºì‹œ ë¬´íš¨í™”] 10% ì´ìƒ ê¸‰ë“±/ê¸‰ë½ ì¢…ëª© ì—†ìŒ")
                return

            logger.info(f"[ìºì‹œ ë¬´íš¨í™”] ê¸‰ë“± {len(surge_tickers)}ê°œ, ê¸‰ë½ {len(plunge_tickers)}ê°œ ê°ì§€")

            # 4. ìºì‹œ ë¬´íš¨í™”
            invalidated_count = 0
            for ticker in all_extreme_tickers:
                try:
                    price_data = realtime_prices[ticker]
                    current_price = price_data['current_price']
                    change_rate = price_data['change_rate']

                    # check_analysis_trigger í˜¸ì¶œ
                    should_invalidate = await analysis_service.check_analysis_trigger(
                        ticker=ticker,
                        current_price=current_price,
                        change_rate=change_rate
                    )

                    if should_invalidate:
                        await analysis_service.invalidate_cache(ticker)
                        invalidated_count += 1
                        direction = "ê¸‰ë“±" if change_rate > 0 else "ê¸‰ë½"
                        logger.info(f"  ğŸ“Œ {ticker} ìºì‹œ ë¬´íš¨í™” ({direction} {change_rate:+.1f}%)")

                except Exception as e:
                    logger.warning(f"  âš ï¸ {ticker} ìºì‹œ ë¬´íš¨í™” ì‹¤íŒ¨: {e}")

            logger.info(f"âœ… [ìºì‹œ ë¬´íš¨í™”] ì™„ë£Œ - {invalidated_count}ê°œ ì¢…ëª© ìºì‹œ ë¬´íš¨í™”")

        except Exception as e:
            logger.warning(f"[ìºì‹œ ë¬´íš¨í™”] ì‹¤ì‹œê°„ ê°€ê²© ì¡°íšŒ ì‹¤íŒ¨: {e}")

    except Exception as e:
        logger.error(f"âŒ [ìºì‹œ ë¬´íš¨í™”] ì‹¤íŒ¨: {e}", exc_info=True)


async def generate_morning_report_job():
    """ì¥ ì‹œì‘ ë¦¬í¬íŠ¸ ìƒì„± (08:00, í‰ì¼)"""
    try:
        logger.info("â° [ì¥ ì‹œì‘ ë¦¬í¬íŠ¸] ìƒì„± ì‹œì‘")
        report_service = get_report_service()
        today = datetime.now()

        report = await report_service.generate_morning_report(today)

        # DBì— ì €ì¥
        from app.db.database import get_db
        from app.db.models import ReportResult
        import json

        with get_db() as db:
            date_str = today.strftime('%Y-%m-%d')

            # ê¸°ì¡´ ë¦¬í¬íŠ¸ í™•ì¸
            existing = db.query(ReportResult).filter(
                ReportResult.date == date_str,
                ReportResult.report_type == 'morning'
            ).first()

            if existing:
                # ì—…ë°ì´íŠ¸
                existing.content = json.dumps(report, ensure_ascii=False)
                existing.generated_at = datetime.now()
                logger.info(f"ğŸ“ [ì¥ ì‹œì‘ ë¦¬í¬íŠ¸] DB ì—…ë°ì´íŠ¸")
            else:
                # ì‹ ê·œ ìƒì„±
                new_report = ReportResult(
                    date=date_str,
                    report_type='morning',
                    content=json.dumps(report, ensure_ascii=False),
                    generated_at=datetime.now()
                )
                db.add(new_report)
                logger.info(f"ğŸ“ [ì¥ ì‹œì‘ ë¦¬í¬íŠ¸] DB ì €ì¥")

        logger.info(f"âœ… [ì¥ ì‹œì‘ ë¦¬í¬íŠ¸] ìƒì„± ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ [ì¥ ì‹œì‘ ë¦¬í¬íŠ¸] ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)


async def generate_afternoon_report_job():
    """ì¥ ë§ˆê° ë¦¬í¬íŠ¸ ìƒì„± (15:40, í‰ì¼)"""
    try:
        logger.info("â° [ì¥ ë§ˆê° ë¦¬í¬íŠ¸] ìƒì„± ì‹œì‘")

        # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        trigger_service = get_trigger_service()
        data_service = get_data_service()
        report_service = get_report_service()
        today = datetime.now()

        # 1. ì˜¤í›„ íŠ¸ë¦¬ê±° ê²°ê³¼ ì¡°íšŒ (DBì—ì„œ)
        from app.db.database import get_db
        from app.db.models import TriggerResult, ReportResult
        import json

        date_str = today.strftime('%Y-%m-%d')

        # ê¸‰ë“±ì£¼ ë¦¬ìŠ¤íŠ¸ ìƒì„± (ì„¸ì…˜ ì•ˆì—ì„œ dict ë³€í™˜)
        surge_stocks = []
        with get_db() as db:
            afternoon_triggers = db.query(TriggerResult).filter(
                TriggerResult.date == date_str,
                TriggerResult.session == 'afternoon'
            ).all()

            # ì„¸ì…˜ì´ ì—´ë ¤ìˆì„ ë•Œ dictë¡œ ë³€í™˜
            for trigger in afternoon_triggers:
                surge_stocks.append({
                    'ticker': trigger.ticker,
                    'name': trigger.name,
                    'change_rate': trigger.change_rate,
                    'trigger_type': trigger.trigger_type,
                    'composite_score': trigger.composite_score
                })

        logger.info(f"ì˜¤í›„ íŠ¸ë¦¬ê±° ì¢…ëª© {len(surge_stocks)}ê°œ ì¡°íšŒ ì™„ë£Œ")

        # 2. ì‹œì¥ ìš”ì•½ ë°ì´í„° ìˆ˜ì§‘ (í™•ì¥ëœ í˜•ì‹)
        try:
            market_data = await data_service.get_market_index(today)
            # ExtendedMarketSummary í˜•ì‹ì— ë§ê²Œ ë³€í™˜ (ì–µì› ë‹¨ìœ„)
            market_summary = {
                # KOSPI
                'kospi_close': market_data.get('kospi_close', 0.0),
                'kospi_change': market_data.get('kospi_change', 0.0),
                'kospi_point_change': market_data.get('kospi_point_change', 0.0),
                # KOSDAQ
                'kosdaq_close': market_data.get('kosdaq_close', 0.0),
                'kosdaq_change': market_data.get('kosdaq_change', 0.0),
                'kosdaq_point_change': market_data.get('kosdaq_point_change', 0.0),
                # ê±°ë˜ëŒ€ê¸ˆ (ì› -> ì–µì›)
                'trading_value': int(market_data.get('trading_value', 0) // 100000000),
                # ìˆ˜ê¸‰ - KOSPI (ì› -> ì–µì›)
                'foreign_net_kospi': int(market_data.get('foreign_net_kospi', 0) // 100000000),
                'institution_net_kospi': int(market_data.get('institution_net_kospi', 0) // 100000000),
                'individual_net_kospi': int(market_data.get('individual_net_kospi', 0) // 100000000),
                # ìˆ˜ê¸‰ - KOSDAQ (ì› -> ì–µì›)
                'foreign_net_kosdaq': int(market_data.get('foreign_net_kosdaq', 0) // 100000000),
                'institution_net_kosdaq': int(market_data.get('institution_net_kosdaq', 0) // 100000000),
                'individual_net_kosdaq': int(market_data.get('individual_net_kosdaq', 0) // 100000000),
                # ì‹œì¥ í­
                'advance_count': market_data.get('advance_count', 0),
                'decline_count': market_data.get('decline_count', 0),
                'unchanged_count': market_data.get('unchanged_count', 0)
            }
            logger.info(f"ì‹œì¥ ìš”ì•½ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: KOSPI {market_summary['kospi_close']} ({market_summary['kospi_change']:+.2f}%), "
                       f"KOSDAQ {market_summary['kosdaq_close']} ({market_summary['kosdaq_change']:+.2f}%)")
        except Exception as e:
            logger.warning(f"ì‹œì¥ ìš”ì•½ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ (ê¸°ë³¸ê°’ ì‚¬ìš©): {e}")
            market_summary = {
                'kospi_close': 0.0, 'kospi_change': 0.0, 'kospi_point_change': 0.0,
                'kosdaq_close': 0.0, 'kosdaq_change': 0.0, 'kosdaq_point_change': 0.0,
                'trading_value': 0,
                'foreign_net_kospi': 0, 'institution_net_kospi': 0, 'individual_net_kospi': 0,
                'foreign_net_kosdaq': 0, 'institution_net_kosdaq': 0, 'individual_net_kosdaq': 0,
                'advance_count': 0, 'decline_count': 0, 'unchanged_count': 0
            }

        # 3. ì¥ ë§ˆê° ë¦¬í¬íŠ¸ ìƒì„±
        report = await report_service.generate_afternoon_report(today, market_summary, surge_stocks)

        # 4. DBì— ì €ì¥
        with get_db() as db:
            # ê¸°ì¡´ ë¦¬í¬íŠ¸ í™•ì¸
            existing = db.query(ReportResult).filter(
                ReportResult.date == date_str,
                ReportResult.report_type == 'afternoon'
            ).first()

            if existing:
                # ì—…ë°ì´íŠ¸
                existing.content = json.dumps(report, ensure_ascii=False)
                existing.generated_at = datetime.now()
                logger.info(f"ğŸ“ [ì¥ ë§ˆê° ë¦¬í¬íŠ¸] DB ì—…ë°ì´íŠ¸")
            else:
                # ì‹ ê·œ ìƒì„±
                new_report = ReportResult(
                    date=date_str,
                    report_type='afternoon',
                    content=json.dumps(report, ensure_ascii=False),
                    generated_at=datetime.now()
                )
                db.add(new_report)
                logger.info(f"ğŸ“ [ì¥ ë§ˆê° ë¦¬í¬íŠ¸] DB ì €ì¥")

        logger.info(f"âœ… [ì¥ ë§ˆê° ë¦¬í¬íŠ¸] ìƒì„± ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ [ì¥ ë§ˆê° ë¦¬í¬íŠ¸] ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)


async def batch_collect_financial_data_job():
    """ì¬ë¬´ ë°ì´í„° ë°°ì¹˜ ìˆ˜ì§‘ (00:00, ë§¤ì¼)"""
    try:
        logger.info("â° [ì¬ë¬´ ë°ì´í„° ë°°ì¹˜] ìˆ˜ì§‘ ì‹œì‘")

        # scripts/batch_collect_financial_data.pyì˜ í•¨ìˆ˜ import
        sys.path.insert(0, str(Path(__file__).parent.parent.parent / "scripts"))
        from batch_collect_financial_data import collect_all_financial_data

        await collect_all_financial_data()

        logger.info(f"âœ… [ì¬ë¬´ ë°ì´í„° ë°°ì¹˜] ìˆ˜ì§‘ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ [ì¬ë¬´ ë°ì´í„° ë°°ì¹˜] ìˆ˜ì§‘ ì‹¤íŒ¨: {e}", exc_info=True)


# ============= ìŠ¤ì¼€ì¤„ëŸ¬ ê´€ë¦¬ =============

def start_scheduler():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ë° ì‘ì—… ë“±ë¡"""

    # 1. ì¥ ì‹œì‘ ë¦¬í¬íŠ¸ (08:00, í‰ì¼)
    scheduler.add_job(
        func=generate_morning_report_job,
        trigger=CronTrigger(
            day_of_week='mon-fri',  # ì›”~ê¸ˆ
            hour=8,
            minute=0
        ),
        id='morning_report',
        name='ì¥ ì‹œì‘ ë¦¬í¬íŠ¸ ìƒì„±',
        replace_existing=True
    )

    # 2. ì˜¤ì „ íŠ¸ë¦¬ê±° (09:10, í‰ì¼)
    scheduler.add_job(
        func=run_morning_triggers_job,
        trigger=CronTrigger(
            day_of_week='mon-fri',
            hour=9,
            minute=10
        ),
        id='morning_triggers',
        name='ì˜¤ì „ íŠ¸ë¦¬ê±° ì‹¤í–‰',
        replace_existing=True
    )

    # 3. ì˜¤í›„ íŠ¸ë¦¬ê±° (15:00, í‰ì¼)
    scheduler.add_job(
        func=run_afternoon_triggers_job,
        trigger=CronTrigger(
            day_of_week='mon-fri',
            hour=15,
            minute=0
        ),
        id='afternoon_triggers',
        name='ì˜¤í›„ íŠ¸ë¦¬ê±° ì‹¤í–‰',
        replace_existing=True
    )

    # 4. ì¥ ë§ˆê° ë¦¬í¬íŠ¸ (15:40, í‰ì¼)
    scheduler.add_job(
        func=generate_afternoon_report_job,
        trigger=CronTrigger(
            day_of_week='mon-fri',
            hour=15,
            minute=40
        ),
        id='afternoon_report',
        name='ì¥ ë§ˆê° ë¦¬í¬íŠ¸ ìƒì„±',
        replace_existing=True
    )

    # 5. ì¬ë¬´ ë°ì´í„° ë°°ì¹˜ ìˆ˜ì§‘ (00:00, ë§¤ì¼)
    scheduler.add_job(
        func=batch_collect_financial_data_job,
        trigger=CronTrigger(
            hour=0,
            minute=0
        ),
        id='batch_financial_data',
        name='ì¬ë¬´ ë°ì´í„° ë°°ì¹˜ ìˆ˜ì§‘',
        replace_existing=True
    )

    # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
    scheduler.start()
    logger.info("ğŸ“… ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ë¨")

    # ë“±ë¡ëœ ì‘ì—… ì¶œë ¥
    jobs = scheduler.get_jobs()
    logger.info(f"ğŸ“‹ ë“±ë¡ëœ ì‘ì—…: {len(jobs)}ê°œ")
    for job in jobs:
        next_run = job.next_run_time.strftime("%Y-%m-%d %H:%M:%S") if job.next_run_time else "ì—†ìŒ"
        logger.info(f"  - {job.name} (ë‹¤ìŒ ì‹¤í–‰: {next_run})")


def stop_scheduler():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì •ë¦¬"""
    if scheduler.running:
        scheduler.shutdown(wait=False)
        logger.info("ğŸ“… ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œë¨")
