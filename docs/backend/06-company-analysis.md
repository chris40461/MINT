# ê¸°ì—… ë¶„ì„ ì„œë¹„ìŠ¤ (Company Analysis)

## ğŸ“Œ ë¬¸ì„œ ëª©ì 

ê¸°ì—… ë¶„ì„ ì„œë¹„ìŠ¤ì˜ ì „ì²´ íë¦„, ë°ì´í„° ìˆ˜ì§‘, LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±, ë¶„ì„ ê²°ê³¼ êµ¬ì¡°, ìºì‹± ì „ëµì„ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## ğŸ¯ ê¸°ì—… ë¶„ì„ ê°œìš”

### ëª©ì 
ì¢…ëª©ì— ëŒ€í•œ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„± (ì¬ë¬´ + ê¸°ìˆ  + ë‰´ìŠ¤ + ì‚°ì—… ë¶„ì„)

### ì‹¤í–‰ íŠ¸ë¦¬ê±°
1. **ì‚¬ìš©ì ìš”ì²­**: ëª…ì‹œì  ë¶„ì„ ìš”ì²­
2. **ë°°ì¹˜ ìƒì„±**: ì¥ ë§ˆê° í›„ ì£¼ìš” ì¢…ëª© ìë™ ë¶„ì„
3. **ì´ë²¤íŠ¸ ê¸°ë°˜**: ì¤‘ìš” ê³µì‹œ ë°œìƒ ì‹œ

### ìºì‹± ì „ëµ
- **TTL**: 24ì‹œê°„
- **ë¬´íš¨í™”**: ì¤‘ìš” ê³µì‹œ, ê¸‰ë“±/ê¸‰ë½ (10% ì´ìƒ)

---

## ğŸ”„ ë¶„ì„ íë¦„

```
ì‚¬ìš©ì ìš”ì²­
    â†“
ìºì‹œ ì¡°íšŒ (Redis)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Cache Hit? â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
      â”‚
  YES â”‚ NO
      â”‚
      â†“                    â†“
  ë°˜í™˜ â† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ ë°ì´í„° ìˆ˜ì§‘
                          â”œâ”€ ì¬ë¬´ (DART)
                          â”œâ”€ ë‰´ìŠ¤ (Naver/Firecrawl)
                          â”œâ”€ ê¸°ìˆ ì  (pykrx)
                          â””â”€ ê°€ê²© (pykrx)
                          â†“
                       LLM ë¶„ì„ (Gemini)
                          â†“
                       ê²°ê³¼ ì €ì¥
                          â”œâ”€ DB
                          â””â”€ Redis (ìºì‹œ)
                          â†“
                       ë°˜í™˜
```

---

## ğŸ“Š ë°ì´í„° ìˆ˜ì§‘

### 1. ì¬ë¬´ ë°ì´í„° (DART API)

```python
async def collect_financial_data(ticker: str) -> Dict:
    """
    DART APIë¥¼ í†µí•œ ì¬ë¬´ì œí‘œ ìˆ˜ì§‘
    """
    # DART API í˜¸ì¶œ
    dart_api = DartAPI(api_key=os.getenv("DART_API_KEY"))

    # ìµœê·¼ ë¶„ê¸° ì¬ë¬´ì œí‘œ
    financial_stmt = await dart_api.get_financial_statement(
        corp_code=ticker,
        report_type="Q"  # ë¶„ê¸°
    )

    return {
        "revenue": financial_stmt["ë§¤ì¶œì•¡"],
        "operating_profit": financial_stmt["ì˜ì—…ì´ìµ"],
        "net_profit": financial_stmt["ë‹¹ê¸°ìˆœì´ìµ"],
        "operating_margin": (
            financial_stmt["ì˜ì—…ì´ìµ"] / financial_stmt["ë§¤ì¶œì•¡"] * 100
        ),
        "net_margin": (
            financial_stmt["ë‹¹ê¸°ìˆœì´ìµ"] / financial_stmt["ë§¤ì¶œì•¡"] * 100
        ),
        "roe": financial_stmt["ROE"],
        "roa": financial_stmt["ROA"],
        "debt_ratio": financial_stmt["ë¶€ì±„ë¹„ìœ¨"],
        "current_ratio": financial_stmt["ìœ ë™ë¹„ìœ¨"],
        "per": financial_stmt["PER"],
        "pbr": financial_stmt["PBR"]
    }
```

### 2. ë‰´ìŠ¤ ë°ì´í„° (í¬ë¡¤ë§)

```python
async def collect_news_data(
    company_name: str,
    days: int = 7
) -> List[Dict]:
    """
    ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ í¬ë¡¤ë§
    """
    news_list = []

    # ë„¤ì´ë²„ ê¸ˆìœµ ê²€ìƒ‰
    url = f"https://finance.naver.com/search/searchList.nhn?query={company_name}"

    async with httpx.AsyncClient() as client:
        response = await client.get(url)
        soup = BeautifulSoup(response.text, 'html.parser')

        articles = soup.select('.articleSubject')

        for article in articles[:10]:  # ìµœê·¼ 10ê°œ
            title = article.get_text(strip=True)
            link = article['href']

            # ê¸°ì‚¬ ë³¸ë¬¸ ìˆ˜ì§‘
            detail_response = await client.get(link)
            detail_soup = BeautifulSoup(detail_response.text, 'html.parser')
            content = detail_soup.select_one('.article_body').get_text(strip=True)

            # LLMìœ¼ë¡œ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„
            sentiment = await analyze_sentiment(title + " " + content)

            news_list.append({
                "title": title,
                "link": link,
                "content": content[:500],  # 500ìë¡œ ì œí•œ
                "sentiment": sentiment,  # positive/neutral/negative
                "score": sentiment['score']  # 0-1
            })

    return news_list
```

### 3. ê¸°ìˆ ì  ì§€í‘œ (pykrx)

```python
async def collect_technical_data(ticker: str) -> Dict:
    """
    ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
    """
    from pykrx import stock
    from datetime import datetime, timedelta

    # ìµœê·¼ 60ì¼ ê°€ê²© ë°ì´í„°
    end_date = datetime.now()
    start_date = end_date - timedelta(days=60)

    df = stock.get_market_ohlcv_by_date(
        start_date.strftime("%Y%m%d"),
        end_date.strftime("%Y%m%d"),
        ticker
    )

    # ì´ë™í‰ê·  ê³„ì‚°
    df['MA_5'] = df['ì¢…ê°€'].rolling(window=5).mean()
    df['MA_20'] = df['ì¢…ê°€'].rolling(window=20).mean()
    df['MA_60'] = df['ì¢…ê°€'].rolling(window=60).mean()

    # RSI ê³„ì‚°
    delta = df['ì¢…ê°€'].diff()
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    avg_gain = gain.rolling(window=14).mean()
    avg_loss = loss.rolling(window=14).mean()
    rs = avg_gain / avg_loss
    rsi = 100 - (100 / (1 + rs))

    # MACD ê³„ì‚°
    exp1 = df['ì¢…ê°€'].ewm(span=12, adjust=False).mean()
    exp2 = df['ì¢…ê°€'].ewm(span=26, adjust=False).mean()
    macd = exp1 - exp2
    signal = macd.ewm(span=9, adjust=False).mean()

    # ìµœì‹  ê°’ ë°˜í™˜
    latest = df.iloc[-1]

    return {
        "rsi": rsi.iloc[-1],
        "macd": {
            "value": macd.iloc[-1],
            "signal": signal.iloc[-1],
            "histogram": (macd - signal).iloc[-1]
        },
        "ma_5": latest['MA_5'],
        "ma_20": latest['MA_20'],
        "ma_60": latest['MA_60'],
        "current_vs_ma_20": "ìƒíšŒ" if latest['ì¢…ê°€'] > latest['MA_20'] else "í•˜íšŒ",
        "bollinger_bands": calculate_bollinger_bands(df),
        "support_resistance": calculate_support_resistance(df)
    }
```

---

## ğŸ¤– LLM ë¶„ì„ ì‹¤í–‰

```python
async def generate_analysis(
    ticker: str,
    stock_data: Dict,
    financial_data: Dict,
    news_data: List[Dict],
    technical_data: Dict
) -> Dict:
    """
    LLMì„ í†µí•œ ì¢…í•© ë¶„ì„ ìƒì„±
    """
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = build_company_analysis_prompt(
        ticker=ticker,
        stock_data=stock_data,
        financial_data=financial_data,
        news_data=news_data,
        technical_data=technical_data
    )

    # Gemini API í˜¸ì¶œ
    llm_service = GeminiService()
    response = await llm_service.generate(prompt)

    # ì‘ë‹µ íŒŒì‹±
    parsed = parse_analysis_response(response)

    return {
        "ticker": ticker,
        "name": stock_data['name'],
        "date": datetime.now().date().isoformat(),
        "source": "llm",
        "analysis": {
            "summary": parsed['summary'],
            "financial_analysis": parsed['financial_analysis'],
            "industry_analysis": parsed['industry_analysis'],
            "news_analysis": parsed['news_analysis'],
            "technical_analysis": parsed['technical_analysis'],
            "risk_factors": parsed['risk_factors'],
            "investment_strategy": parsed['investment_strategy']
        },
        "metadata": {
            "generated_at": datetime.now().isoformat(),
            "model": "gemini-2.5-flash",
            "tokens_used": response.usage_metadata.total_token_count,
            "processing_time_ms": response.elapsed_time
        }
    }
```

---

## ğŸ“¦ ë¶„ì„ ê²°ê³¼ êµ¬ì¡°

```python
{
    "ticker": "005930",
    "name": "ì‚¼ì„±ì „ì",
    "date": "2025-11-06",
    "source": "llm",  # or "cache"

    "analysis": {
        "summary": {
            "investment_opinion": "BUY",  # STRONG_BUY, BUY, HOLD, SELL, STRONG_SELL
            "target_price": 85000,
            "current_price": 75000,
            "upside_potential": 13.33,
            "key_insights": [
                "ë°˜ë„ì²´ ìŠˆí¼ ì‚¬ì´í´ ì§„ì…ìœ¼ë¡œ ìˆ˜ìµì„± ê°œì„  ì „ë§",
                "HBM3 ì‹œì¥ ì ìœ ìœ¨ í™•ëŒ€ë¡œ í”„ë¦¬ë¯¸ì—„ í™•ë³´"
            ],
            "confidence_score": 0.85
        },

        "financial_analysis": {
            "profitability": {
                "summary": "ë§¤ì¶œ ì„±ì¥ê³¼ í•¨ê»˜ ì˜ì—…ì´ìµë¥  ê°œì„  ì¤‘",
                "metrics": {...},
                "evaluation": "ì–‘í˜¸"
            },
            "stability": {...},
            "growth": {...},
            "valuation": {...}
        },

        "industry_analysis": {
            "sector": "IT/ë°˜ë„ì²´",
            "industry_trend": "í˜¸í™©",
            "market_position": "ê¸€ë¡œë²Œ 1ìœ„",
            "competitive_advantage": [...],
            "competitors": [...]
        },

        "news_analysis": {
            "period": "2025-10-30 ~ 2025-11-06",
            "sentiment": {
                "positive": 28,
                "neutral": 10,
                "negative": 4,
                "overall_score": 0.75
            },
            "major_news": [...]
        },

        "technical_analysis": {
            "trend": "ìƒìŠ¹",
            "indicators": {...},
            "support_resistance": {...}
        },

        "risk_factors": [
            {
                "type": "ì‹œì¥ ë¦¬ìŠ¤í¬",
                "description": "...",
                "severity": "ì¤‘ê°„"
            }
        ],

        "investment_strategy": {
            "short_term": {...},
            "medium_term": {...},
            "long_term": {...}
        }
    },

    "metadata": {
        "generated_at": "2025-11-06T10:30:15",
        "expires_at": "2025-11-07T10:30:15",
        "model": "gemini-2.5-flash",
        "tokens_used": 1850,
        "processing_time_ms": 3250
    }
}
```

---

## ğŸ’¾ ì €ì¥ ë° ìºì‹±

```python
async def save_and_cache_analysis(
    ticker: str,
    date: str,
    analysis: Dict
):
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ DBì™€ Redisì— ì €ì¥
    """
    # 1. DB ì €ì¥
    await db.execute("""
        INSERT INTO analysis (
            ticker, date, investment_opinion, target_price,
            current_price, upside_potential, confidence_score,
            key_insights, financial_analysis, industry_analysis,
            news_analysis, technical_analysis, risk_factors,
            investment_strategy, model, tokens_used, processing_time_ms,
            created_at, expires_at
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """, (
        ticker,
        date,
        analysis['analysis']['summary']['investment_opinion'],
        analysis['analysis']['summary']['target_price'],
        # ... ë‚˜ë¨¸ì§€ í•„ë“œ
    ))

    # 2. Redis ìºì‹± (TTL: 24ì‹œê°„)
    cache_key = f"analysis:{ticker}:{date}"
    await redis.setex(
        cache_key,
        86400,  # 24ì‹œê°„
        json.dumps(analysis, ensure_ascii=False)
    )

    logger.info(f"Saved and cached analysis for {ticker}")
```

---

## ğŸ”„ ìºì‹œ ë¬´íš¨í™”

```python
async def invalidate_analysis_cache(ticker: str, reason: str):
    """
    ë¶„ì„ ìºì‹œ ë¬´íš¨í™”

    Args:
        ticker: ì¢…ëª© ì½”ë“œ
        reason: ë¬´íš¨í™” ì‚¬ìœ  (disclosure/price_shock/manual)
    """
    # í•´ë‹¹ ì¢…ëª©ì˜ ëª¨ë“  ìºì‹œ ì‚­ì œ
    pattern = f"analysis:{ticker}:*"
    keys = await redis.keys(pattern)

    if keys:
        await redis.delete(*keys)
        logger.warning(
            f"Invalidated {len(keys)} cache keys for {ticker}. "
            f"Reason: {reason}"
        )

    # ì¬ë¶„ì„ ìŠ¤ì¼€ì¤„ë§
    if reason in ["disclosure", "price_shock"]:
        await schedule_reanalysis(ticker)
```

### ë¬´íš¨í™” ì¡°ê±´

```python
# 1. ì¤‘ìš” ê³µì‹œ ë°œìƒ
@app.webhook("/dart/disclosure")
async def on_disclosure(disclosure_data: Dict):
    """DART ê³µì‹œ ì›¹í›…"""
    if disclosure_data['importance'] == 'high':
        await invalidate_analysis_cache(
            ticker=disclosure_data['ticker'],
            reason="disclosure"
        )

# 2. ê¸‰ë“±/ê¸‰ë½ (10% ì´ìƒ)
async def monitor_price_changes():
    """ê°€ê²© ë³€ë™ ëª¨ë‹ˆí„°ë§"""
    stocks = await get_all_stocks()

    for stock in stocks:
        change_rate = calculate_change_rate(stock)

        if abs(change_rate) >= 10:
            await invalidate_analysis_cache(
                ticker=stock['ticker'],
                reason="price_shock"
            )
```

---

## ğŸš€ ë°°ì¹˜ ë¶„ì„

```python
async def batch_analyze_top_stocks():
    """
    ì¥ ë§ˆê° í›„ ì£¼ìš” ì¢…ëª© ìë™ ë¶„ì„

    ì‹¤í–‰ ì‹œê°„: 15:40 (ì¥ ë§ˆê° í›„)
    ëŒ€ìƒ: ì‹œê°€ì´ì•¡ Top 50 + ê¸‰ë“±ì£¼
    """
    # Top 50 ì¢…ëª©
    top_stocks = await get_top_stocks_by_market_cap(limit=50)

    # ê¸‰ë“±ì£¼
    trigger_stocks = await get_todays_trigger_stocks()

    # ì¤‘ë³µ ì œê±°
    all_tickers = list(set(
        [s['ticker'] for s in top_stocks] +
        [s['ticker'] for s in trigger_stocks]
    ))

    logger.info(f"Batch analyzing {len(all_tickers)} stocks")

    # ë³‘ë ¬ ë¶„ì„ (5ê°œì”©)
    for i in range(0, len(all_tickers), 5):
        batch = all_tickers[i:i+5]

        tasks = [
            analyze_stock(ticker)
            for ticker in batch
        ]

        await asyncio.gather(*tasks)

        # Rate Limit ê³ ë ¤ (5ì´ˆ ëŒ€ê¸°)
        await asyncio.sleep(5)

    logger.info("Batch analysis completed")
```

---

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### 1. ë°ì´í„° ìˆ˜ì§‘ ë³‘ë ¬í™”

```python
async def collect_all_data_parallel(ticker: str) -> Dict:
    """
    ëª¨ë“  ë°ì´í„°ë¥¼ ë³‘ë ¬ë¡œ ìˆ˜ì§‘

    ìˆœì°¨ ì‹¤í–‰: 15ì´ˆ
    ë³‘ë ¬ ì‹¤í–‰: 5ì´ˆ
    """
    tasks = [
        collect_stock_data(ticker),
        collect_financial_data(ticker),
        collect_news_data(ticker),
        collect_technical_data(ticker)
    ]

    results = await asyncio.gather(*tasks)

    return {
        "stock": results[0],
        "financial": results[1],
        "news": results[2],
        "technical": results[3]
    }
```

### 2. í”„ë¡¬í”„íŠ¸ ìµœì í™”

```python
# ë¶ˆí•„ìš”í•œ ë°ì´í„° ì œê±°
news_summary = compress_news_data(news_data)  # ì „ì²´ ë³¸ë¬¸ â†’ ì œëª© + ìš”ì•½

# í† í° ìˆ˜ ì²´í¬
token_count = count_tokens(prompt)
if token_count > 3000:
    # í”„ë¡¬í”„íŠ¸ ì••ì¶•
    prompt = compress_prompt(prompt, max_tokens=3000)
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸

```python
@pytest.mark.asyncio
async def test_company_analysis():
    """ê¸°ì—… ë¶„ì„ E2E í…ŒìŠ¤íŠ¸"""
    analysis_service = AnalysisService()

    # ë¶„ì„ ì‹¤í–‰
    result = await analysis_service.analyze("005930")

    # ê²€ì¦
    assert result['ticker'] == "005930"
    assert result['analysis']['summary']['investment_opinion'] in [
        'STRONG_BUY', 'BUY', 'HOLD', 'SELL', 'STRONG_SELL'
    ]
    assert result['analysis']['summary']['target_price'] > 0
    assert len(result['analysis']['risk_factors']) >= 3

    # ìºì‹œ í™•ì¸
    cached = await redis.get("analysis:005930:2025-11-06")
    assert cached is not None
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [DART API ë¬¸ì„œ](https://opendart.fss.or.kr/guide/main.do)
- [pykrx ë¬¸ì„œ](https://github.com/sharebook-kr/pykrx)

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-11-06
**ì‘ì„±ì**: SKKU-INSIGHT ê°œë°œíŒ€
